---
layout: post.hbs
title: "Facebook: Aspirational Government?"
summary: Plowing through one PR crisis after another, could its long term goals
  not be purely financial gain?
feat_image: /static/images/facebook_gif.gif
publish_date: 2020-07-25T16:00:19.176Z
update_date: 2020-07-25T16:00:00.000Z
---
Is it far-fetched to speculate that Facebook’s long term goal may entail becoming more than a mere place to sell ads to people, but actually a global powerhouse for mass manipulation of ideologies, perceptions and beliefs? Some might argue that it is already the case, but I want to further explore this thought.

First, the response Facebook has regarding the perceived negative impact of its actions (and inactions) makes me wonder to what extend the company cares for maximizing its profits, at least on the long term. The ongoing ad boycott is nothing but a minor dent in the company’s ever increasing revenue (more on that later).

Secondly, the company knows it has the world’s most sought after digital advertising channel, where small/medium are unable to avoid it to reach their audiences. This gives the company a phenomenally powerful dominant position.

Lastly, it’s worth mentioning that the level of control the CEO has, coupled with the lack of actual oversight over a company with such a global impact on our lives is astonishing. Mark Zuckerberg is the chairman of the board of directors and controls 60% of the voting shares¹, giving him full control over the company’s future. His word is law. For most companies, a board of directors has actual voting power. If that was the case for Facebook, it could have produced quite different outcomes in the company’s past couple of years’ mishaps. But under a single ruler’s will, things are different.

And to me, that’s why it seems Facebook is able to take such a different stance when compared to other big tech companies.

<hr>

## Catering to Power

Facing continuous pressure from governments and institutions, Twitter was the first of the Big Tech companies that decided to ban political ads² altogether from its platform. Google followed suit³ with a similar approach and restricted targeted ads at people based on their political leanings.

Facebook went ahead and did nothing of the sort.

Not only did the company said no restrictions would apply to political targeting, the company doubled down saying it wouldn’t do any sort of fact checking whatsoever⁴. In a speech at Georgetown University, Mark Zuckerberg said “People having the power to express themselves at scale is a new kind of force in the world\[…]”, conveniently not highlighting that some have a greater opportunity to propagate their message, provided they pay for that privilege.

Facebook understands that maintaining its dominant position on the long term goes beyond maintaining its current revenue flow. Its aim is to avoid being subject to government scrutiny, potential fines but most importantly real regulation.

The best strategy lays in aligning and playing along with current political powers.

While Twitter finally stepped up and started fact-checking and labeling Donald Trump’s tweets, Facebook allowed for his inflammatory rhetoric to remain available and distributable on the platform.

![A Tweet by Jason Stirman, product R&D at Facebook stating "I'm a Facebook employee that completely disagrees with Mark's decision to do nothing about Trump's recent posts, which clearly incite violence".](/static/images/stirman_tweet.jpeg "A Tweet by Jason Stirman, product R&D at Facebook")

<p class="u-ImageDescription"><a href="https://twitter.com/stirman" target="_blank">Jason Stirman</a>, product R&D at Facebook.</p>

So does Facebook doesn’t care at all about what employees, users and clients think of its actions? After all, Mark Zuckerberg did say privately that “\[…]all these advertisers will be back on the platform soon enough.”⁵ To some degree he isn’t wrong: first, most companies participating in the boycott are doing it for only one-month; secondly, the highest-spending 100 brands only account for 6% of the company’s ad revenue⁶, meaning most mid and small sized companies who can’t afford to not spend in advertising will keep on doing so.

The same way the 2017 boycott against YouTube had no financial impact for the company on the long term, the same will be true for Facebook.

Tangent aside, it appears that Facebook seems to care at least for one specific individual. Following the internal outburst against Mark Zuckerberg’s decision to keep the post up, the CEO had a “productive” phone call with the U.S. president⁷. This political proximity is nothing new. In September 2019, Mark Zuckerberg met Donald Trump in the White House⁸ soon followed by a dinner in October⁹. The content of those meetings and calls? Undisclosed.

Facebook’s VP Andrew Bosworth said Donald Trump got elected in 2016 because “he ran the single best digital ad campaign I’ve ever seen from any advertiser”.¹⁰ That is if you put aside internal employee communications revealing that the company knew of Cambridge Analytica extracting and misusing their user data almost a year before the 2016 U.S. elections¹¹; or ignore the fact that Facebook and Cambridge Analytica worked side-by-side for the 2016 Donald Trump campaign¹².

Nonetheless, advertisers purchased more than $887m worth of political ads on Facebook since May 2018. Of that total, at least $21m were spent by Facebook’s №1 customer for political ads: the campaign to reelect President Donald Trump in 2020¹³.

So is the motive for having such proximity to ensure future revenue from political ads don’t dry up? $1b revenue from political ads seems quite irrelevant to Facebook’s $69.5b global revenue in 2019¹⁴. So maybe, the motive goes beyond money.

## Blurring The Lines

IfI had to speculate, I’d say Facebook’s mission isn’t about connecting the world anymore but acting on that connection and influence it. As we look at its ever expanding reach while it “connects” the world, we assume its primary aim is to modify its users’ consumer behavior for classic advertising with *maybe* a sprinkle of politics in the middle.

But what if there were another behavior modification goal, geared towards more abstract concepts such as thought, opinions and beliefs? What if they actually instrumentalized their platform to nudge societies to shift their standards on ethics and moral? Or a nation’s political leaning? Or individuals’ acceptance or refusal of certain ideologies and tilting preference from democratic to authoritarian governments?

I’m not saying Facebook doesn’t already influence many aspects of our society, the difference being that until now it seems this influence was a by-product from its algorithms, network effect, the ability to get tricked into providing user data and general disregard for collaterals.

In fact, Facebook has never made a point in hiding their ambition of manipulating its users for its own goals.

In 2010, the company’s scientists claim to have boosted voter turnout in midterm elections by 340k through experimentation with a peer-pressure methods by displaying a “I Voted” sticker¹⁵.

In 2012, Facebook modified the newsfeed of 700k users to display more positive or negative content, demonstrably modifying their mood by observing a change in their comment patterns which became more positive or negative during the experiment¹⁶.

Now in 2020, the company plans on increasing voter turnout for the U.S. election through a “Voting Information Center” that will “reduce the effectiveness of malicious networks that might try to take advantage of uncertainty and interfere with the election by getting clear, accurate and authoritative information to people”¹⁷. In a historically opaque company that excuses itself with platitudes, what guarantees do we have that this voter turnout is fair? How will we ever know that the algorithms employed to boost turnouts won’t be geared at benefitting one party over another? And how would we know the actual reason behind an eventual manipulation? Could it be done as a favor for a government in return for less scrutiny from regulators? Who would know?

## Governing: The Ideal Segue?

Facebook certainly has an ambivalent stance when it comes to helping its users, considering the rampant misinformation it allows to circulate. It knowingly exacerbates the polarization of its user base¹⁸, leading to an overall lower quality of life for those subject to these attacks on the mind.


But I’m less worried about incompetent behavior resulting in negative social consequences than I am about the potential marriage of technocrats with governmental power: so far tech companies have mainly encountered push back and been held accountable by either the market, organized workers or governments.


Even though a market boycott is deemed a plausible threat, as we’ve seen so far it has posed no issue to the company’s revenue as advertisers will inevitably want to tap into Facebook’s billions of eyeballs.

![A tweet by Chris Masterson, ex Product Designer at Facebook/Instagram, stating "Honestly embarrassed to so say I ever worked at Facebook".](/static/images/masterson_tweet.jpeg "A tweet by Chris Masterson, ex Product Designer at Facebook/Instagram.")

<p class="u-ImageDescription"><a href="https://twitter.com/chrismasterson" target="_blank">Chris Masterson</a>, ex Product Designer at Facebook/Instagram.</p>